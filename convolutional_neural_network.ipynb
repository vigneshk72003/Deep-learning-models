{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:    FOR THIS CNN WE CANT IMPLEMENT IN GOOGLE COLAB BECAUSE OF LARGE IMAGES SIZE, SO WE WILL USE JUPYTER NOTEBOOK**"
      ],
      "metadata": {
        "id": "Y94tqSi_1Awk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf #for cnn we need only tensorflow library\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "5EMUxfEb0kCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AindJFIr0pQ3",
        "outputId": "7770b28c-e43a-4d52-cc15-ec73514a0255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set(for this see keras API form)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_trainingset=ImageDataGenerator(rescale=1/255,zoom_range=0.2,shear_range=0.2,horizontal_flip=True)\n",
        "\n",
        "#see here by using ImageDataGenerator() class i can bring training and test set, through an object(main_trainingset)\n",
        "#the paramters says, rescale=this will convert i/p image to pixels in (1/255)size\n",
        "#since, model should be built with all the features that can be made with an original image,then only the model can predict the test image,eventhough when the image is edited form\n",
        "#so we use shear range=0.2(20%), it tilts the image, zoom range=0.2(20%),zooms the image, horizantal_flip=True it flips the image  horizontally\n",
        "#this shear,zoom parameters will allow model to predict the edited of the original image correctly\n",
        "\n",
        "training_set=main_trainingset.flow_from_directory(\"dataset/training_set\",target_size=(64,64),\n",
        "                                      batch_size=32,class_mode=\"binary\")\n",
        "#in this through object(main_trainingset),iam calling flow_from_directory(), dataset/training_set this says the path where the file is stored\n",
        "#target_size, since model can't accept all i/p image size,iam making each i/p image in particular size\n",
        "#batch_size=32, it says at a time 32 images are trained using the model\n",
        "#class_mode, it says after converting image to pixel what format should each cell contains, here each cell will be binary\n",
        "#AT LAST STROING IN training_set variable"
      ],
      "metadata": {
        "id": "32PhGo991NSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_testset=ImageDataGenerator(rescale=1/255) #while giving the test image has input, we should not make any changes, except image to pixels\n",
        "testset=main_testset.flow_from_directory(\"dataset/test_set\",target_size=32,batch_size=32,class_mode=\"binary\")\n",
        "#same as mentioned above"
      ],
      "metadata": {
        "id": "eWgO28ci36ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN(SINCE EACH ONE OF THE PART IS HAVING MORE LAYERS WE NEED TO HAVE AT A TIME SO ADD IS USED )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#repeat similar as ann\n",
        "cnn=tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "qRnPGtESDp0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(input_shape=[64,64,3],filters=32,kernel_size=3,activation=\"relu\"))\n",
        "#same format,but since convolution, we use Conv2D() class\n",
        "#input_shape says the size of image,which we have taken in target size as(64,64) and 3 denotes color image which is 3D\n",
        "#filters says no. of times the featured detector can be, and kernel_size is the size of featured detector\n",
        "#kernel_size is feature detecor matrix size\n",
        "#activation same as we did in ann for weightage(synapse)"
      ],
      "metadata": {
        "id": "0_8EqtW3EHEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "\n",
        "#using Maxpool2d(), pool_size says the pool matrix size in which row and coloumn are same, so only row=column=2\n",
        "#strides=no.of steps to move the matrix"
      ],
      "metadata": {
        "id": "mNdq_WKwEKtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation=\"relu\"))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "\n",
        "#for each convolutional layer we get a pool layers also, but here input_shape will not come\n",
        "#because that is needed only in starting convolutional layer"
      ],
      "metadata": {
        "id": "l0wiaoSAGTWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten(units=128,activation=\"relu\")) #no need of parameter"
      ],
      "metadata": {
        "id": "12GKv6s9HQjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128,activation=\"relu\"))   #since full connection leads to ann, we use dense()\n",
        "#only for output activation=sigmoid,since cnn connected to ann is complex , using high value for units"
      ],
      "metadata": {
        "id": "ZzheP-RZHXNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
        "#since the ouput is classified into 0 or 1 i use units=1"
      ],
      "metadata": {
        "id": "jXas-f7aIM3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "MaOHwg7IJNjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)#since already it is to long process making epochs as 25\n",
        "#validation_data is like y"
      ],
      "metadata": {
        "id": "x-0tv64vJMSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction(we know predict needs to be in 2D, but we are giving an image so we need to convert image to 2D array, and further addding the batch value along with this array, which means the test image will result will be in 2D format along with batch )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "#see keras for loading the image\n",
        "test_image=image.load_img(\"dataset/single_predictions/cat_or_dogs1.jpeg\",target_size=[64,64]) #image.load_img is used to load image from the folder\n",
        "#the loaded image should also be in same size has used in cnn\n",
        "test_image=image.img_to_array(test_image) #used tp make the image to array, which is needed for predict\n",
        "test_image=np.expand_dims(test_image,axis=0) #this will expand the array by adding the batch which is needed,\n",
        "#since each 32 images are trained in 1 batch\n",
        "result=cnn.predict(test_image)\n",
        "training_set.class_indices #NOTE: in before concepts we know what is dependent variable, but here in cnn in given images we don't know\n",
        "#which is dependent term, so using training_set indices we can classify the terms as 0 &1 becuase the model has already done for this training_set\n",
        "if(result[0][0]==1): #[0][], since result has 2D array,batch now iam taking the first dimensions from both,because in predict we are going to give\n",
        "#only 1 image,which will index 0 array and batch each\n",
        "  predictions=\"dog\"\n",
        "else:\n",
        "  predictions=\"cat\""
      ],
      "metadata": {
        "id": "5uvuB66TlQKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "id": "VKsyErZ3GPE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}